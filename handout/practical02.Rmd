---
title: "Méthodes biostatistiques"
subtitle: "Modèle linéaire et applications"
---

Les paramètres suivants doivent être définis dans R ou RStudio afin de reproduire les analyses présentées dans ce document. Les packages `ggplot2`{.pkg}, `hrbrthemes`{.pkg}, `directlabels`{.pkg}, `cowplot`{.pkg}, `texreg`{.pkg}, `Hmisc`{.pkg}, `rms`{.pkg}, `mfp`{.pkg}, `multcomp`{.pkg} et `reshape2`{.pkg} ne font pas partie de la distribution R et doivent être installés si nécessaire :

```{r, eval = FALSE}
install.packages(c("ggplot2", "hrbrthemes", "directlabels", "cowplot",
                     "texreg", "rms", "mfp", "multcomp", "reshape2"))
```

Les dépendances de ces packages seront installés automatiquement. On supposera également que les instructions R sont exécutées dans un répertoire de travail avec les fichiers de données accessibles dans un sous-répertoire `data/`. Si ce n'est pas le cas, il suffit de créer un sous-répertoire `data/` et d'y enregistrer les fichiers de données, ou de redéfinir les chemins d'accès dans les instructions de lecture des fichiers de données ci-après.

```{r, message = FALSE}
library(hrbrthemes)
library(directlabels)
library(cowplot)
library(texreg)
library(rms)            ## Imports: Hmisc, ggplot2
library(mfp)
library(multcomp)
library(reshape2)
options(digits = 6, show.signif.stars = FALSE)
theme_set(theme_ipsum(base_size = 11))
```

# Régression linéaire simple

<div class="outline">
Soit $y_i$ la réponse observée sur l'individu $i$, et $x_i$ sa valeur observée pour le prédicteur $x$. Le modèle de régression linéaire s'écrit $$y_i = \beta_0+\beta_1x_i+\varepsilon_i,$$ où $\beta_0$ représente l'ordonnée à l'origine (\emph{intercept}) et $\beta_1$ la pente (\emph{slope}) de la droite de régression, et $\varepsilon_i\sim\mathcal{N}(0,\sigma^2)$ est un terme d'erreur (résidus, supposés indépendants).

En minimisant les différences quadratiques entre les valeurs observées et les valeurs prédites (principe des MCO), on peut estimer les coefficients de régression, $\hat\beta_0$ et $\hat\beta_1$ : $$\begin{array}{l} \hat\beta_0 = \bar y - \hat\beta_1\bar x\\ \hat\beta_1 = \sum(y_i-\bar y)(x_i-\bar x)/\sum(x_i-\bar x)^2\\ \end{array}$$ Sous $H_0$, le rapport entre l'estimé de la pente ($\hat\beta_1$, de variance $\frac{\text{SSR}/(n-2)}{(n-1)s_x^2}$) et son erreur standard suit une loi de Student à $(n-2)$ degrés de liberté.
</div>

## Chargement des données

Les données utilisées proviennent d'une étude sur le volume expiratoire maximum (en litre par seconde) et sont disponibles dans le fichier [`fev.rda`](data/fev.rda) :

```{r}
load("data/fev.rda")
str(FEV)
```

## Description des variables

Un résumé numérique pour l'ensemble des variables peut être obtenu avec `summary`{pkg="base"} (on pourrait utiliser la fonction `describe`{pkg="Hmisc"} du package `Hmisc`{.pkg} pour avoir plus de détails) :

```{r}
summary(FEV)
```

On propose quelques pré-traitements pour faciliter les analyses subséquentes :

```{r}
describe(FEV$age)
FEV$age[FEV$age == 3] <- 4         ## low counts in extreme categories
FEV$age[FEV$age == 19] <- 18
FEV$height <- FEV$height * 2.54  ## inches -> centimeters
FEV$lfev <- log(FEV$fev)
```

On va s'intéresser à la relation entre la variable `fev` (voire son log, `lfev`) et les autres variables numériques, `age` et `height`. Voici quelques représentations graphiques préliminaires avec `ggplot2`{.pkg}, dans un premier temps univariées, puis bivariées :

```{r, warning = FALSE}
## switch to long format in order to get a facet variable
d <- melt(FEV[,c("id", "age", "fev", "height")], id.vars = "id")
levels(d$variable) <- c("Age (yr.)", "FEV (l/s)", "Height (cm)")
p <- ggplot(data = d, aes(x = value)) +
       geom_line(stat = "density") +
       geom_rug(size = .5, alpha = .3) +
       facet_wrap(~ variable, ncol = 3, scales = "free")  +
       labs(x = "", y = "Density")
p
```

```{r, warning = FALSE}
## switch to long format in order to get a facet variable
d <- melt(FEV[,c("id", "sex", "smoke", "age", "fev")], measure.vars = 4:5)
levels(d$variable) <- c("Age (yr.)", "FEV (l/s)")
p <- ggplot(data = d, aes(x = sex, y = value)) +
       geom_boxplot() +
       facet_grid(variable ~ smoke, scales = "free_y") +
       labs(x = NULL, y = NULL)
p
```

```{r}
p <- ggplot(data = FEV, aes(x = age, y = fev, color = sex)) +
       geom_point(alpha = 0.5) +
       geom_smooth(method = "loess", se = FALSE) +
       scale_color_manual(values = c("steelblue", "orange")) +
       guides(color = FALSE) +
       labs(x = "Age (yr.)", y = "FEV (l/s)")
p1 <- direct.label(p + aes(label = sex))
p <- ggplot(data = FEV, aes(x = height, y = fev, color = sex)) +
       geom_point(alpha = 0.5) +
       geom_smooth(method = "loess", se = FALSE) +
       scale_color_manual(values = c("steelblue", "orange")) +
       guides(color = FALSE) +
       labs(x = "Height (cm)", y = "FEV (l/s)")
p2 <- direct.label(p + aes(label = sex))
plot_grid(p1, p2)
```

## Modélisation

Un premier modèle de régression que l'on peut considérer est simplement la relation entre FEV et taille sur l'ensemble de l'échantillon. On obtient les paramètres estimés d'un tel modèle à l'aide de `lm`{pkg="stats"} :

```{r}
m <- lm(fev ~ height, data = FEV)
summary(m)
```

Les graphiques précédents suggérant toutefois une teandance non linéaire lorsque l'on stratifie sur le sexe, on peut regarder si les conditions de validité du modèle sont bien vérifiées, en particulier en analysant les résidus de ce modèle.

```{r}
yhat <- fitted(m)
rstd <- rstandard(m)
p <- ggplot(data = NULL, aes(x = yhat, y = rstd)) +
       geom_hline(yintercept = 0, linetype = 1, color = grey(.3)) +
       geom_hline(yintercept = c(-2,2), linetype = 2, color = grey(.3)) +
       geom_point() +
       geom_smooth(method = "loess", se = FALSE, color = "lightcoral") +
       labs(x = "Fitted values", y = "Residuals")
p
```

On pourrait utiliser une transformation de Box-Cox ($\tfrac{y^{\lambda}-1}{\lambda}$) ou de Tukey ($y^{\lambda}$) pour sélectionner une transformation optimale de la variable réponse pour linéariser la relation, mais on va simplement considérer que la FEV varie linéairement avec le cube de la taille, ce qui revient à modéliser la racine cubique de la FEV, $\sqrt[3]{\text{fev}}$. En pratique, cela reste assez proche de ce que nous donnerait une transformation de Tukey (on trouve $\lambda = 0.263 \approx 1/3$ en utilisant les instructions R `v <- boxcox(m); v$x[which.max(v$y)]`) :

```{r}
m <- lm(I(fev ^ (1/3)) ~ height, data = FEV)
```

```{r, echo = FALSE}
yhat <- fitted(m)
names(yhat) <- FEV$id
rstd <- rstandard(m)
p <- ggplot(data = NULL, aes(x = yhat, y = rstd)) +
       geom_hline(yintercept = 0, linetype = 1, color = grey(.3)) +
       geom_hline(yintercept = c(-2,2), linetype = 2, color = grey(.3)) +
       geom_point() +
       annotate("text", x = yhat[abs(rstd) > 3], y = rstd[abs(rstd) > 3],
                label = names(yhat[abs(rstd) > 3]), size = 3, hjust = -0.5) +
       geom_smooth(method = "loess", se = FALSE, color = "lightcoral") +
       labs(x = "Fitted values", y = "Residuals", caption = ~ "Model considering height" ^3)
p
```

Il reste quelques observations avec des résidus élevés aux deux extrêmes de la distribution des valeurs prédites (les observations avec des résidus supérieurs à 3 en valeur absolue sont annotés avec l'identifiant du sujet). On peut vérifier si ces observations influencent les paramètres estimés à l'aide des mesures d'influence par "jacknife" fournies par R :

```{r}
influence.measures(m)
```

## Autres approches pour la non linéarité

Voici trois approches alternatives permettant de s'affranchir de la stricte linéarité telle qu'assumée dans le modèle de régression linéaire : dans un premier modèle (`m1`), on peut inclure un terme quadratique pour rendre compte du changement de pente apparent pour des tailles supérieures à 160 cm ; sur la même idée, on peut utiliser des polynômes de degré variable, ici d'ordre 3 (`m2`) ; enfin, une approche plus souple par rapport aux polynômes consisterait à utiliser des splines cubiques restreints (`m3`), ici à l'ordre 3 également. Dans le cas des modèles `m2` et `m3`, les fonctions `pol` et `rcs` sont fournies par le package `rms`{.pkg} :

```{r}
m1 <- lm(fev ~ height + I(height^2), data = FEV)
m2 <- lm(fev ~ pol(height, 3), data = FEV)        ## or poly(height, 3, raw = TRUE)
m3 <- lm(fev ~ rcs(height, 3), data = FEV)
```

Une dernière approche consiste à utiliser des polynömes fractionnaires, l'avantage étant comme dans le cas des splines une plus grande flexibilité et une validation croisée permettant de sélectionner le degré optimal :

```{r}
m4 <- mfp(fev ~ fp(height, df = 4, select = .05), data = FEV)
m4
```

Les prédictions de ces différents modèles sont affichées dans la figure suivante.

```{r, echo = FALSE}
dd <- data.frame(height = 110:190)
yhat <- cbind.data.frame(dd, y1 = predict(m1, dd), y2 = predict(m2, dd),
                         y3 = predict(m3, dd), y4 = predict(m4, dd))
p <- ggplot(data = FEV, aes(x = height, y = fev)) +
       geom_point(color = grey(.3), alpha = .5) +
       geom_line(data = melt(yhat, measure.vars = 2:5), aes(x = height, y = value, color = variable), size = 1) +
       scale_color_ipsum(name = "", labels = c("height + height²", "pol(height, 3)", "rcs(height, 3)", "fp(height, 4)")) +
       theme(legend.position = c(0.1, 0.88)) +
       labs(x = "Height (cm)", y = "FEV (l/s)")
p
```

# Régression, ANOVA et test t

## Régression sur variable catégorielle

Avec R, il est important de s'assurer que les variables catégorielles sont bien traitées comme des facteurs, à l'exception des variables binaires codées en 0/1 qui ne posent pas de problème particulier (ni en tant que variable réponse, ni en tant que prédicteur). R utilise des contrastes de traitement par défaut, ce qui signifie que la catégorie de référence à laquelle sont comparés tous les autres niveaux est le premier niveau du facteur.

Voici une application dans laquelle on modélise la FEV en fonction du statut (fumeur/non-fumeur) :

```{r}
levels(FEV$smoke)
m <- lm(fev ~ smoke, data = FEV)
summary(m)
confint(m)
```

On obtiendra le même résultat, au signe près, avec un test t supposant l'égalité des variances :

```{r}
t.test(fev ~ smoke, data = FEV, var.equal = TRUE)
```

Considérons maintenant l'âge, discrétiser en 4 classes d'effectifs équilibrés, et comparons les résultats d'une régression linéaire sur variable numérique (`age`), d'une régression linéaire sur variable catégorielle (`age4`) et d'une ANOVA :

```{r}
FEV$age4 <- cut2(FEV$age, g = 4)
r <- with(FEV, summarize(fev, age4, smean.sd))
r
r$fev[2:4] - r$fev[1]
m1 <- lm(fev ~ age, data = FEV)
m2 <- lm(fev ~ age4, data = FEV)
m3 <- aov(fev ~ age4, data = FEV)
```

Le modèle `m2` fournit 3 coefficients de régression pour la variable âge à 4 modalités ; chacun de ces coefficients représente la différence de moyenne de la catégorie en question par rapport à la première catégorie (4–9 ans) :

```{r}
summary(m2)
```

On retrouvera facilement les différentiels de moyennes :

```{r}
r <- with(FEV, summarize(fev, age4, smean.sd))
r
```

Voici l'idée schématisée sous forme graphique (les boîtes à moustaches sont alignées sur les centres de classe de la variable `age4`) :

```{r, echo = FALSE}
FEV$age4c <- as.numeric(as.character(cut2(FEV$age, g = 4, levels.mean = TRUE)))
p <- ggplot(data = FEV, aes(x = age, y = fev)) +
       geom_boxplot(aes(x = age4c, y = fev, group = age4c), outlier.size = -1, color = grey(.3), fill = "transparent") +
       geom_jitter(color = grey(.7), alpha = .5, width = .05) +
       geom_smooth(method = "lm", color = "steelblue") +
       labs(x = "Age (yr.)", y = "FEV (l/s)")
p
FEV$age4c <- NULL
```

# Régression multiple

<div class="outline">
Dans le cas où la variable réponse est continue, le modèle de régression multiple s'écrit simplement comme une combinaison linéaire de différents termes représentant les effets de chaque régresseur : $$\mathbb{E}(y\mid x_1,x_2,\dots) = \beta_0 + \beta_1x_1 + \beta_2x_2 + \dots.$$

Les coefficients de régression représentent l'effet partiel de chaque prédicteur, c'est-à-dire l'effet de l'augmentation d'une unité de $x_j$ sur $y$ lorsque tous les autres prédicteurs sont maintenus constants. On peut tester l'égalité de l'ensemble des coefficients (test F), la nullité d'un coefficient (test t) ou d'un ensemble de coefficients (test F partiel).
</div>

Un autre modèle possible consiste à considérer le statut fumeur et un potentiel facteur de confusion, à savoir l'âge puisqu'en dessous de 9 ans il n'y a pas de fumeurs et qu'au-dessus on a bien deux sous-populations.

```{r, echo = FALSE}
p <- ggplot(data = FEV, aes(x = age, y = fev, color = smoke)) +
       geom_point(alpha = 0.5) +
       geom_smooth(method = "loess", se = FALSE) +
       annotate("rect", xmin = -Inf, ymin = -Inf, xmax = 9, ymax = Inf, fill = grey(.7), alpha = .5) +
       scale_color_manual(values = c("steelblue", "orange")) +
       guides(color = FALSE) +
       labs(x = "Age (yr.)", y = "FEV (l/s)")
direct.label(p + aes(label = smoke))
```

Voici le modèle en question :

```{r}
m1 <- lm(fev ~ smoke, data = FEV)
m2 <- lm(fev ~ age + smoke, data = FEV)
screenreg(list(m1,m2))
```

Comme les modèles sont emboîtés, le test du coefficient pour la variable `age` peut se retrouver par simple comparaison de modèles (par test F ou par test du rapport de vraisemblance) :

```{r}
anova(m1, m2)
```

Et voici le modèle incluant un terme d'interaction entre les variables `age` et `smoke` :

```{r}
m3 <- lm(fev ~ age + smoke + age:smoke, data = FEV)
summary(m3)
```

Le graphique suivant résume la situation, avec des intervalles de confiance à 95 % (non simultanés !) :

```{r}
p <- ggplot(data = FEV, aes(x = age, y = fev, color = smoke)) +
       geom_point(alpha = 0.5) +
       geom_smooth(method = "lm", show.legend = FALSE) +
       scale_color_manual("", values = c("steelblue", "orange")) +
       guides(color = FALSE) +
       labs(x = "Age (yr.)", y = "FEV (l/s)")
direct.label(p + aes(label = smoke))
```

Notons que l'on peut toujours utiliser la fonction `ols`{pkg="rms"} au lieu de la fonction `lm`{pkg="stats"} de base. Les sorties sont plus riches, il est possible d'introduire une régularisation de type "ridge" et `rms`{.pkg} fournit des procédure de validation et de calibration du modèle. les commandes de post-estimation (en langage Stata) sont plus intéressantes : on pourrait par exemple calculer les valeurs prédites de `fev` en fonction de `smoke` conditionnellement à un ensemble fixe et pré-spécifié de valeurs de `age`.

En dernier lieu, si l'on rajoute la variable `height` et `height`^2^, on remarquera que l'interaction `age:smoke` n'est plus significative :

```{r}
m <- ols(fev ~ age + smoke + age:smoke + pol(height, 2), data = FEV, x = TRUE)
m
```

```{r}
d <- expand.grid(age = 9:18, smoke = levels(FEV$smoke),
                 height = seq(120, 180, by = 10))
yhat <- predict(m, d, se.fit = TRUE)
d <- cbind.data.frame(d, yhat)
head(d)
```

Approche alternative (spécifique au package `rms`{.pkg}) :

```{r}
Predict(m, age = 18, height = seq(160, 180, by = 2),
        smoke = "current smoker", conf.type = "simult")
```

# Analyse de covariance

<div class="outline">
Soit $y_{ij}$ la $j$ème observation dans le groupe $i$. À l'image du modèle d'ANOVA à un facteur, le modèle d'ANCOVA s'écrit $$ y_{ij} = \mu+\alpha_i+\beta(x_{ij}-\bar x)+\varepsilon_{ij},$$ où $\beta$ est le coefficient de régression liant la réponse $y$ et le cofacteur $x$ (continu), avec $\bar x$ la moyenne générale des $x_{ij}$, et toujours un terme d'erreur $\varepsilon_{ij}\sim \mathcal{N}(0,\sigma^2)$.

Notons que l'on fait l'hypothèse que $\beta$ est le même dans chaque groupe. Cette hypothèse de parallélisme peut se vérifier en testant la significativité du terme d'interaction $\alpha\beta$. La réponse moyenne ajustée pour l'effet du co-facteur numérique s'obtient simplement comme $\bar\alpha_i+\hat\beta(\bar x_i-\bar x)$, où $\bar x_i$ est la moyenne des $x$ dans le $i$ème groupe.
</div>

## Chargement des données

Les données `anorexia`{pkg="MASS"} portent sur une étude clinique dans laquelle on s'intéresse à l'amélioration de l'état de santé (mesurée par le gain de poids) de patientes anorexiques prises en charge par thérapie familiale (`FT`) ou thérapie comportementale (`CBT`). Un groupe contrôle est également disponible. Les données sont situées dans le packge `MASS`{.pkg}.

```{r}
data(anorexia, package = "MASS")
str(anorexia)
```

## Description des variables

Voici un bref résumé numérique, suivi d'une description graphique des données :

```{r}
anorexia$Prewt <- anorexia$Prewt * 0.45    ## lbs -> kg
anorexia$Postwt <- anorexia$Postwt * 0.45
anorexia$Treat <- relevel(anorexia$Treat, ref = "Cont")
describe(anorexia)
```

```{r}
p <- ggplot(data = anorexia, aes(x = Prewt, y = Postwt, color = Treat)) +
       geom_point() +
       geom_smooth(method = "lm", se = FALSE) +
       scale_color_manual("", values = c("grey30", "steelblue", "orange")) +
       guides(color = FALSE) +
       labs(x = "Weight at entry (kg)", y = "Weight at discharge (kg)")
direct.label(p + aes(label = Treat))
```

## Modélisation

Dans un premier temps, après avoir exclus le groupe contrôle qui pourrait faire l'objet d'analyses séparées avec un ensemble de contrastes appropriés, on souhaite vérifier s'il existe ou non une interaction entre le type de thérapie et le poids de sortie, après avoir contrôlé pour le poids en entrée :

```{r}
m0 <- lm(Postwt ~ Prewt + Treat, data = anorexia, subset = Treat != "Cont")
m1 <- lm(Postwt ~ Prewt + Treat + Prewt:Treat, data = anorexia, subset = Treat != "Cont")
anova(m0, m1)
```

En l'absence d'interaction, on pourra donc estimer le gain de poids moyen entre les deux groupes, quel que soit le poids en entrée :

```{r}
summary(m0)
confint(m0)
```

# Exercices d'application {.tabset}

Dans cette application, on travaillera avec le data frame `birthwt`{pkg="MASS"} qui contient des données issues d'une étude rétrospective dans lequel on s'intéresse aux facteurs de risque d'accoucher d'un bébé avec un poids inférieur à la norme (< 2.5 kg selon les normes américaines des années 80). Les variables d'intérêt sont le poids du bébé (`bwt`), l'âge (`age`) et le poids (`lwt`, en pounds) de la mère ainsi que son origine ethnique (`race`), les antécédents d'hypertension (`ht`) et le status fumeur (`smoke`).

Les données sont disponibles dans le package `MASS`{.pkg}. Il est nécessaire de charger au préalable le package ou de le spécifier lors de l'importation :

```{r}
data(birthwt, package = "MASS")
summary(birthwt)
```

Voici une vue partielle des données individuelles et agrégées :

```{r}
birthwt$lwt <- birthwt$lwt * 0.45
birthwt$race <- factor(birthwt$race, levels = 1:3, labels = c("white", "black", "other"))
birthwt$smoke <- factor(birthwt$smoke, levels = 0:1, labels = c("non-smoker", "smoker"))
p <- ggplot(data = birthwt, aes(x = lwt, y = bwt, color = smoke)) +
       geom_point() +
       geom_smooth(method = "lm", se = FALSE) +
       scale_color_manual(values = c("steelblue", "orange")) +
       guides(color = FALSE) +
       facet_wrap(~ race, ncol = 3) +
       geom_text(data = data.frame(lwt = c(45,90), bwt = c(1500,4500),
                                   race = "white", smoke = c("smoker", "non-smoker")),
                 aes(x = lwt, y = bwt, label = smoke), color = c("orange", "steelblue")) +
       labs(x = "Mother weight (kg)", y = "Baby weight (g)")
p
```

## Sélection de modèle

On considérera le modèle de base suivant : `bwt ~ lwt + race`.

1. Quelles sont les variables que l'on pourrait ajouter pour améliorer la portée ou la pertinence d'un tel modèle sur le plan de l'interprétation clinique ? Ces variables sont-elles significatives ?
2. En utilisant une procédure de sélection automatique (`step`{pkg="stats"}), indiquer parmi l'ensemble des variables lesquelles pourraient être considérées comme significatives au seuil de 5 %, sans tenir compte des problèmes inhérents à la sélection pas à pas.
3. Comparer avec les résultats obtenus par une approche reposant sur une pénalisation de type "elasticnet" (package `elasticnet`{.pkg} ou `glmnet`{.pkg}).

## Tests spécifiques

1. Considérons le modèle `bwt ~ lwt + race + smoke`. Estimer les paramètres du modèle avec leurs intervalles de confiance à 95 %.
2. On souhiate comparer le groupe `white` aux deux groupes réunis `black+other` tout en ajustant sur les deux autres variables du modèle. Proposer une approche reposant sur l'utilisation de contrastes (package `multcomp`{.pkg} ou `rms`{.pkg}).
3. Existe t-il une différence signifciative entre les mères qui fument dans la catégorie `white` et celles qui fument dans la catégorie `black` ?

## Estimation par bootstrap

1. Estimer les paramètres du modèle `bwt ~ age + ht` et construire un intervalle de confiance à 95 % pour le coefficient de régression de `ht`.
2. Comparer avec une approche par bootstrap (package `boot`{.pkg} ou procédure manuelle) pour la construction d'un intervalle de confiance.
