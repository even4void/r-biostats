---
title: "Modèle linéaire et applications"
---

Les paramètres suivants doivent être définis dans R ou RStudio afin de reproduire les analyses présentées dans ce document. Les packages **ggplot2**, **hrbrthemes**, **directlabels**, **cowplot**, **rms**, **mfp**, **multcomp** et **reshape2** ne font pas partie de la distribution R et doivent être téléchargés au préalable (`install.packages(c("ggplot2", "hrbrthemes", "directlabels", "cowplot", "rms", "mfp", "multcomp", "reshape2"))`) s'ils ne sont pas déjà installés. Les dépendances de ces packages seront installés automatiquement. On supposera également que les instructions R sont exécutées dans un répertoire de travail avec les fichiers de données accessibles dans un sous-répertoire `data/`. Si ce n'est pas le cas, il suffit de créer un sous-répertoire `data/` et d'y enregistrer les fichiers de données, ou de redéfinir les chemins d'accès dans les instructions de lecture des fichiers de données ci-après.
```{r, message = FALSE}
library(hrbrthemes)
library(directlabels)
library(cowplot)
library(rms)            ## Hmisc, ggplot2
library(mfp)
library(multcomp)
library(reshape2)
options(digits = 6, show.signif.stars = FALSE)
theme_set(theme_ipsum(base_size = 11))
```


# Régression linéaire simple et multiple

## Chargement des données

Les données utilisées proviennent d'une étude sur le volume expiratoire maximum (en litre par seconde)

```{r}
load("data/fev.rda")
str(FEV)
```

## Description des variables

Un résumé numérique pour l'ensemble des variables peut être obtenu avec `summary()` (on pourrait utiliser la fonction `describe()` de **Hmisc** pour avoir plus de détails) :
```{r}
summary(FEV)
```

On propose quelques pré-traitements pour faciliter les analyses subséquentes :
```{r}
describe(FEV$age)
FEV$age[FEV$age == 3] <- 4         ## low counts in extreme categories
FEV$age[FEV$age == 19] <- 18
FEV$height <- FEV$height * 2.54  ## inches -> centimeters
FEV$lfev <- log(FEV$fev)
```

On va s'intéresser à la relation entre la variable `fev` (voire son log, `lfev`) et les autres variables numériques, `age` et `height`. Voici quelques représentations graphiques préliminaires avec **ggplot2**, dans un premier temps univariées, puis bivariées :
```{r, warning = FALSE}
## switch to long format in order to get a facet variable
d <- melt(FEV[,c("id", "age", "fev", "height")], id.vars = "id")
levels(d$variable) <- c("Age (yr.)", "FEV (l/s)", "Height (cm)")
p <- ggplot(data = d, aes(x = value)) +
       geom_line(stat = "density") +
       geom_rug(size = .5, alpha = .3) +
       facet_wrap(~ variable, ncol = 3, scales = "free")  +
       labs(x = "", y = "Density")
p
```

```{r, warning = FALSE}
## switch to long format in order to get a facet variable
d <- melt(FEV[,c("id", "sex", "smoke", "age", "fev")], measure.vars = 4:5)
levels(d$variable) <- c("Age (yr.)", "FEV (l/s)")
p <- ggplot(data = d, aes(x = sex, y = value)) +
       geom_boxplot() +
       facet_grid(variable ~ smoke, scales = "free_y") +
       labs(x = NULL, y = NULL)
p
```


```{r}
p <- ggplot(data = FEV, aes(x = age, y = fev, color = sex)) +
       geom_point(alpha = 0.5) +
       geom_smooth(method = "loess", se = FALSE) +
       scale_color_manual(values = c("steelblue", "orange")) +
       guides(color = FALSE) +
       labs(x = "Age (yr.)", y = "FEV (l/s)")
p1 <- direct.label(p + aes(label = sex))
p <- ggplot(data = FEV, aes(x = height, y = fev, color = sex)) +
       geom_point(alpha = 0.5) +
       geom_smooth(method = "loess", se = FALSE) +
       scale_color_manual(values = c("steelblue", "orange")) +
       guides(color = FALSE) +
       labs(x = "Height (cm)", y = "FEV (l/s)")
p2 <- direct.label(p + aes(label = sex))
plot_grid(p1, p2)
```

## Modélisation

Un premier modèle que l'on peut considérer est simplement la relation entre FEV et taille sur l'ensemble de l'échantillon :
```{r}
m <- lm(fev ~ height, data = FEV)
summary(m)
```

Les graphiques précédents suggérant toutefois une teandance non linéaire lorsque l'on stratifie sur le sexe, on peut regarder si les conditions de validité du modèle sont bien vérifiées, en particulier en analysant les résidus de ce modèle.
```{r}
yhat <- fitted(m)
rstd <- rstandard(m)
p <- ggplot(data = NULL, aes(x = yhat, y = rstd)) +
       geom_hline(yintercept = 0, linetype = 1, color = grey(.3)) + 
       geom_hline(yintercept = c(-2,2), linetype = 2, color = grey(.3)) + 
       geom_point() +
       geom_smooth(method = "loess", se = FALSE, color = "lightcoral") +
       labs(x = "Fitted values", y = "Residuals")
p
```

On pourrait utiliser une transformation de Box-Cox ($\tfrac{y^{\lambda}-1}{\lambda}$) ou de Tukey ($y^{\lambda}$) pour sélectionner une transformation optimale de la variable réponse pour linéariser la relation, mais on va simplement considérer que la FEV varie linéairement avec le cube de la taille, ce qui revient à modéliser la racine cubique de la FEV, $\sqrt[3]{\text{fev}}$. En pratique, cela reste assez proche de ce que nous donnerait une transformation de Tukey (on trouve $\lambda = 0.263 \approx 1/3$ en utilisant les instructions R `v <- boxcox(m); v$x[which.max(v$y)]`) :
```{r}
m <- lm(I(fev ^ (1/3)) ~ height, data = FEV)
```

```{r, echo = FALSE}
yhat <- fitted(m)
names(yhat) <- FEV$id
rstd <- rstandard(m)
p <- ggplot(data = NULL, aes(x = yhat, y = rstd)) +
       geom_hline(yintercept = 0, linetype = 1, color = grey(.3)) + 
       geom_hline(yintercept = c(-2,2), linetype = 2, color = grey(.3)) + 
       geom_point() +
       annotate("text", x = yhat[abs(rstd) > 3], y = rstd[abs(rstd) > 3], 
                label = names(yhat[abs(rstd) > 3]), size = 3, hjust = -0.5) +
       geom_smooth(method = "loess", se = FALSE, color = "lightcoral") +
       labs(x = "Fitted values", y = "Residuals", caption = ~ "Model considering height" ^3)
p
```

Il reste quelques observations avec des résidus élevés aux deux extrêmes de la distribution des valeurs prédites (les observations avec des résidus supérieurs à 3 en valeur absolue sont annotés avec l'identifiant du sujet). On peut vérifier si ces observations influencent les paramètres estimés à l'aide des mesures d'influence par _jacknife_ fournies par R :
```{r}
influence.measures(m)
```
 
## Autres approches pour la non linéarité

Voici trois approches alternatives permettant de s'affranchir de la stricte linéarité telle qu'assumée dans le modèle de régression linéaire : dans un premier modèle (`m1`), on peut inclure un terme quadratique pour rendre compte du changement de pente apparent pour des tailles supérieures à 160 cm ; sur la même idée, on peut utiliser des polynômes de degré variable, ici d'ordre 3 (`m2`) ; enfin, une approche plus souple par rapport aux polynômes consisterait à utiliser des splines cubiques restreints (`m3`), ici à l'ordre 3 également :  
```{r}
m1 <- lm(fev ~ height + I(height^2), data = FEV)
m2 <- lm(fev ~ poly(height, 3), data = FEV)
m3 <- lm(fev ~ rcs(height, 3), data = FEV)
```

Une dernière approche consiste à utiliser des polynömes fractionnaires, l'avantage étant comme dans le cas des splines une plus grande flexibilité et une validation croisée permettant de sélectionner le degré optimal :
```{r}
m4 <- mfp(fev ~ fp(height, df = 4, select = .05), data = FEV)
m4
```

Les prédcitions de ces différents modèles sont affichées dans la figure suivante.

```{r, echo = FALSE}
dd <- data.frame(height = 110:190)
yhat <- cbind.data.frame(dd, y1 = predict(m1, dd), y2 = predict(m2, dd), 
                         y3 = predict(m3, dd), y4 = predict(m4, dd))
p <- ggplot(data = FEV, aes(x = height, y = fev)) +
       geom_point(color = grey(.3), alpha = .5) +
       geom_line(data = melt(yhat, measure.vars = 2:5), aes(x = height, y = value, color = variable), size = 1) +
       scale_color_ipsum(name = "", labels = c("height + height²", "poly(height, 3)", "rcs(height, 3)", "fp(height, 4)")) +
       theme(legend.position = c(0.1, 0.88)) +
       labs(x = "Height (cm)", y = "FEV (l/s)")
p
```

polynômes fractionnaires, splines
rcs

## Régression multiple


# Régression et ANOVA

# Analyse de covariance

# Sélection de modèles

# Régression et régularisation

# Exercices d'application {.tabset}
